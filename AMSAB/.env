# Copy this to .env and fill in your values
OPENAI_API_KEY=sk-dummy
ANTHROPIC_API_KEY=sk-dummy

# Models
ARCHITECT_MODEL=gpt-4o-mini
WORKER_MODEL=gpt-4o

# Optional: use local Llama 3 via Ollama for planning
USE_OLLAMA_FOR_PLANNING=true
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# Docker
DOCKER_IMAGE=amsab-worker:latest
DOCKER_NETWORK=none
DOCKER_TIMEOUT_SECONDS=120
